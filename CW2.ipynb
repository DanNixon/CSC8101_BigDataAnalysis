{
 "metadata": {
  "name": "",
  "signature": "sha256:069b981f6d903b7365b15b30b80cd417d5f197c2db865ca32b9d498a3ae2afb2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "netflix_raw_data = sc.textFile('/home/ubuntu/BigDataAnalysis/data/netflix_movie_titles.txt')\n",
      "canonical_raw_data = sc.textFile('/home/ubuntu/BigDataAnalysis/data/movie_titles_canonical.txt')\n",
      "\n",
      "import unicodedata\n",
      "\n",
      "def clean_title_string(title):\n",
      "    # Remove accents, symbols and whitespace and convert to lowercase\n",
      "    # (http://stackoverflow.com/questions/517923/what-is-the-best-way-to-remove-accents-in-a-python-unicode-string)\n",
      "    nfkd_form = unicodedata.normalize('NFKD', title)\n",
      "    return u\"\".join([c.lower() for c in nfkd_form if c.isalnum() and not unicodedata.combining(c)])\n",
      "\n",
      "def parse_netflix_data(row):\n",
      "    data = row.split(',')\n",
      "    \n",
      "    title = data[2].strip()\n",
      "    try:\n",
      "        year = int(data[1])\n",
      "    except:\n",
      "        year = 0\n",
      "        \n",
      "    return (year, title, clean_title_string(title), int(data[0])) # year, title, clean title, id\n",
      "    \n",
      "def parse_canonical_data(row):\n",
      "    data = row.rpartition(',')\n",
      "    \n",
      "    title = data[0].strip()\n",
      "    try:\n",
      "        year = int(data[2])\n",
      "    except:\n",
      "        year = 0\n",
      "        \n",
      "    return (year, (title, clean_title_string(title))) # year, (title, clean title)\n",
      "\n",
      "netflix_data = netflix_raw_data.map(parse_netflix_data)\n",
      "canonical_data = canonical_raw_data.map(parse_canonical_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "netflix_data.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "[(2003, u'Dinosaur Planet', u'dinosaurplanet', 1),\n",
        " (2004, u'Isle of Man TT 2004 Review', u'isleofmantt2004review', 2),\n",
        " (1997, u'Character', u'character', 3),\n",
        " (1994, u\"Paula Abdul's Get Up & Dance\", u'paulaabdulsgetupdance', 4),\n",
        " (2004, u'The Rise and Fall of ECW', u'theriseandfallofecw', 5)]"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "canonical_data.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "[(2009, (u'Avatar', u'avatar')),\n",
        " (2001, (u'Am\\xe9lie', u'amelie')),\n",
        " (1987, (u'Full Metal Jacket', u'fullmetaljacket')),\n",
        " (1982, (u'E.T.: The Extra-Terrestrial', u'ettheextraterrestrial')),\n",
        " (1996, (u'Independence Day', u'independenceday'))]"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grouped = canonical_data.groupByKey()\n",
      "films_for_year = grouped.collectAsMap()\n",
      "print(\"Number of years: {}\".format(len(films_for_year)))\n",
      "\n",
      "#films_for_year[2007].data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of years: 112\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_netflix_alias(netflix_film):\n",
      "    title = None\n",
      "    year = netflix_film[0]\n",
      "    if year in films_for_year:\n",
      "        title_results = [f for f in films_for_year[netflix_film[0]] if f[1] == netflix_film[2]]\n",
      "        title = title_results[0][0] if len(title_results) == 1 else None\n",
      "    return (netflix_film[3], title)\n",
      "\n",
      "netflix_aliases = netflix_data.map(find_netflix_alias).filter(lambda f: f[1] is not None)\n",
      "print(\"Number of aliases: {}\".format(netflix_aliases.count()))\n",
      "\n",
      "netflix_aliases.saveAsTextFile('/home/ubuntu/out.txt')\n",
      "\n",
      "netflix_aliases.take(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of aliases: 3708\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "[(3, u'Character'),\n",
        " (12, u'My Favorite Brunette'),\n",
        " (15, u'Neil Diamond: Greatest Hits Live'),\n",
        " (17, u'7 Seconds'),\n",
        " (18, u'Immortal Beloved'),\n",
        " (30, u\"Something's Gotta Give\"),\n",
        " (55, u'Jade'),\n",
        " (58, u'DragonHeart'),\n",
        " (77, u'Congo'),\n",
        " (78, u'Jingle All the Way')]"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aliases = netflix_aliases.collectAsMap()\n",
      "print(len(aliases))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}